{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Split Dataset\n",
    "\n",
    "split dataset into { train, validation, test } sets\n",
    "\n",
    "- train: 70%\n",
    "- validation: 10%\n",
    "- test: 20%"
   ],
   "id": "4088556f97309306"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-27T06:15:26.788934Z",
     "start_time": "2025-02-27T06:15:26.779550Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "data_dir = os.path.abspath(\"...\")\n",
    "\n",
    "torch.manual_seed(42)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b9ed2bc830>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T06:15:26.819275Z",
     "start_time": "2025-02-27T06:15:26.803956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_dataset(dataset: torch.Tensor, train_ratio=0.7, val_ratio=0.1):\n",
    "    \"\"\"Split dataset into train, val, and test sets.\n",
    "\n",
    "    :return: Tuple of (train_dataset, val_dataset, test_dataset)\n",
    "    \"\"\"\n",
    "    n_dataset = dataset.shape[0]\n",
    "    train_size = int(n_dataset * train_ratio)\n",
    "    val_size = int(n_dataset * val_ratio)\n",
    "    # test_size = n_dataset - train_size - val_size\n",
    "\n",
    "    indices = torch.randperm(n_dataset)\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size : train_size + val_size]\n",
    "    test_indices = indices[train_size + val_size :]\n",
    "\n",
    "    return dataset[train_indices], dataset[val_indices], dataset[test_indices]"
   ],
   "id": "f94ca18b9f1be3e1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split ADHD Dataset",
   "id": "28d9857d4c8f8003"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T06:15:26.865960Z",
     "start_time": "2025-02-27T06:15:26.835640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "adhd_dataset = torch.load(\n",
    "    os.path.join(data_dir, \"eeg_adhd.pt\"), weights_only=True\n",
    ").permute(0, 2, 1)\n",
    "train_set_adhd, val_set_adhd, test_set_adhd = split_dataset(adhd_dataset)\n",
    "\n",
    "print(\"Train set:\", train_set_adhd.size())\n",
    "print(\"Val set:\", val_set_adhd.size())\n",
    "print(\"Test set:\", test_set_adhd.size())"
   ],
   "id": "69eeb60b688d4a86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: torch.Size([71, 19, 9250])\n",
      "Val set: torch.Size([10, 19, 9250])\n",
      "Test set: torch.Size([21, 19, 9250])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split Contorl Dataset",
   "id": "5e8f9ee86a6595ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T06:15:26.912798Z",
     "start_time": "2025-02-27T06:15:26.883246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "control_dataset = torch.load(\n",
    "    os.path.join(data_dir, \"eeg_control.pt\"), weights_only=True\n",
    ").permute(0, 2, 1)\n",
    "train_set_control, val_set_control, test_set_control = split_dataset(control_dataset)\n",
    "\n",
    "print(\"Train set:\", train_set_control.size())\n",
    "print(\"Val set:\", val_set_control.size())\n",
    "print(\"Test set:\", test_set_control.size())"
   ],
   "id": "a6313fb2aaf63e56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: torch.Size([50, 19, 9250])\n",
      "Val set: torch.Size([7, 19, 9250])\n",
      "Test set: torch.Size([15, 19, 9250])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Save with labels\n",
    "\n",
    "- 1: ADHD\n",
    "- 0: Contorl (non-ADHD)"
   ],
   "id": "14945e906d72833f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T06:15:26.990982Z",
     "start_time": "2025-02-27T06:15:26.976964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_dataset(dataset, labels, filename):\n",
    "    labeled_dataset = {\"data\": dataset, \"label\": labels}\n",
    "    save_path = os.path.join(data_dir, filename)\n",
    "    torch.save(labeled_dataset, save_path)"
   ],
   "id": "33ab949b81855179",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T06:15:27.131928Z",
     "start_time": "2025-02-27T06:15:26.995983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_set = torch.cat((train_set_adhd, train_set_control), dim=0)\n",
    "train_labels = torch.cat(\n",
    "    (\n",
    "        torch.ones((train_set_adhd.size(0)), dtype=torch.int8),\n",
    "        torch.zeros((train_set_control.size(0)), dtype=torch.int8),\n",
    "    ),\n",
    "    dim=0,\n",
    ")\n",
    "\n",
    "# Shuffle data for training.\n",
    "assert train_set.size(0) == train_labels.size(0), \"Data and label size mismatch\"\n",
    "random_indices = torch.randperm(train_set.size(0))\n",
    "print(f\"Random indices: {random_indices}\")\n",
    "\n",
    "save_dataset(train_set[random_indices], train_labels[random_indices], \"train.pt\")"
   ],
   "id": "64fd56f6c47b66cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random indices: tensor([ 11,  12,  76,  54,   9,  43,  64,  17, 104, 103,  16,  71,  46,  29,\n",
      "         39, 117,   7,  94,  40,  57,  98,  91,  53,  42,  61,  84,  37, 101,\n",
      "         86,  68, 111,  99,  90,  22,  58,  82,  50,  93,   4, 107,   1,  38,\n",
      "        118,  24, 110,  33,  78,  97,  21,  14,   5,  92,  25,  23,  18, 102,\n",
      "        116, 109,  35,  52,  31, 100,  85, 106,  28,  55,  81,  36,  77,  60,\n",
      "         10,  47,  89,  45,  15,  83,  26,  30,   3,  48,   2,  80,  20,  27,\n",
      "         44,  32,  74,  79, 108,  73,  62, 113,  41,  72, 120,  96,  95, 115,\n",
      "         59,  88,  67,  69,  19,  63,  66,   8, 105,  75,  49,  70,  65,  13,\n",
      "         51,   0,  56, 119, 112,  34,  87, 114,   6])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T06:15:27.196033Z",
     "start_time": "2025-02-27T06:15:27.165018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_set = torch.cat((val_set_adhd, val_set_control), dim=0)\n",
    "val_labels = torch.cat(\n",
    "    (\n",
    "        torch.ones((val_set_adhd.size(0)), dtype=torch.int8),\n",
    "        torch.zeros((val_set_control.size(0)), dtype=torch.int8),\n",
    "    ),\n",
    "    dim=0,\n",
    ")\n",
    "save_dataset(val_set, val_labels, \"val.pt\")"
   ],
   "id": "982bd03f8ac3b3bc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T06:15:27.273012Z",
     "start_time": "2025-02-27T06:15:27.227971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_set = torch.cat((test_set_adhd, test_set_control), dim=0)\n",
    "test_labels = torch.cat(\n",
    "    (\n",
    "        torch.ones((test_set_adhd.size(0)), dtype=torch.int8),\n",
    "        torch.zeros((test_set_control.size(0)), dtype=torch.int8),\n",
    "    ),\n",
    "    dim=0,\n",
    ")\n",
    "save_dataset(test_set, test_labels, \"test.pt\")"
   ],
   "id": "e1aceba927364375",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save metadata",
   "id": "e88ca53ac6dd0be0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T06:15:27.319617Z",
     "start_time": "2025-02-27T06:15:27.305090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metadata = {\n",
    "    \"name\": \"EEG data for ADHD / Control children\",\n",
    "    \"description\": \"EEG dataset for ADHD classification.\",\n",
    "    \"license\": \"CC BY 4.0\",\n",
    "    \"train_size\": list(train_set.size()),\n",
    "    \"val_size\": list(val_set.size()),\n",
    "    \"test_size\": list(test_set.size()),\n",
    "    \"data_length\": train_set.size()[2],\n",
    "    \"channel\": train_set.size()[1],\n",
    "    \"label\": {1: \"ADHD\", 0: \"Control\"},\n",
    "}\n",
    "\n",
    "for k, v in metadata.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "metadata_path = os.path.join(data_dir, \"metadata.json\")\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)"
   ],
   "id": "c4e10927e5f18f91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: EEG data for ADHD / Control children\n",
      "description: EEG dataset for ADHD classification.\n",
      "license: CC BY 4.0\n",
      "train_size: [121, 19, 9250]\n",
      "val_size: [17, 19, 9250]\n",
      "test_size: [36, 19, 9250]\n",
      "data_length: 9250\n",
      "channel: 19\n",
      "label: {1: 'ADHD', 0: 'Control'}\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
