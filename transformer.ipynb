{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ae57df0e0079b5",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "Train Base ViT model for IEEE EEG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7f090fe145c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import secrets\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm, trange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, auc\n",
    "import warnings\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def join_path(*args):\n",
    "    return os.path.join(\"/content/drive/MyDrive\", *args)\n",
    "\n",
    "def clear():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c8041bd814fa2e",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea53ea2dcbcdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique ID\n",
    "while True:\n",
    "    experiment_id = secrets.token_hex(8)\n",
    "    if not os.path.exists(join_path(f\"{experiment_id}.pth\")) and not os.path.exists(join_path(f\"{experiment_id}.json\")):\n",
    "        break\n",
    "print(\"ID:\", experiment_id)\n",
    "\n",
    "# Fix random seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Settings\n",
    "ARGS = {\n",
    "    \"id\": experiment_id,\n",
    "    \"name\": \"4 Head Self attention\",\n",
    "    \"model_path\": join_path(f\"{experiment_id}.pth\"),\n",
    "    \"batch\": 256,\n",
    "    \"grad_step\": 1,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 1e-4,\n",
    "    \"weight_decay\": 1e-2,\n",
    "    \"patience\": 2,\n",
    "}\n",
    "DATA = {\n",
    "    \"train_path\": join_path(\"data\", \"train.pt\"),\n",
    "    \"test_path\": join_path(\"data\", \"test.pt\"),\n",
    "    \"val_path\": join_path(\"data\", \"val.pt\"),\n",
    "    \"channel\": 19,\n",
    "    \"length\": 2560,\n",
    "    \"labels\": [\"control\", \"ADHD\"],\n",
    "}\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77313d992057683",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "972e55f36ba88295",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T11:33:30.314900Z",
     "start_time": "2025-02-21T11:33:30.301507Z"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    \"\"\"Stop training when loss does not decrease\n",
    "\n",
    "    :param patience: number of epochs to wait before stopping\n",
    "    :param save_path: path to save the best model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience, save_path):\n",
    "        self._min_loss = np.inf\n",
    "        self._patience = patience\n",
    "        self._path = save_path\n",
    "        self.__counter = 0\n",
    "\n",
    "    def should_stop(self, model, loss):\n",
    "        \"\"\"Check if training should stop\n",
    "\n",
    "        :param model: model to save\n",
    "        :param loss: current loss\n",
    "        \"\"\"\n",
    "        if loss < self._min_loss:\n",
    "            self._min_loss = loss\n",
    "            self.__counter = 0\n",
    "            torch.save(model.state_dict(), self._path)\n",
    "        elif loss > self._min_loss:\n",
    "            self.__counter += 1\n",
    "            if self.__counter >= self._patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def load(self, model):\n",
    "        \"\"\"Load best model\n",
    "\n",
    "        :param model: model structure\n",
    "        \"\"\"\n",
    "        model.load_state_dict(torch.load(self._path))\n",
    "        return model\n",
    "\n",
    "    @property\n",
    "    def counter(self):\n",
    "        return self.__counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941f295f0046c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmupScheduler:\n",
    "    \"\"\"Warmup learning rate and dynamically adjusts learning rate based on training loss.\n",
    "\n",
    "    :param optimizer: torch optimizer\n",
    "    :param initial_lr: initial learning rate\n",
    "    :param min_lr: minimum learning rate\n",
    "    :param warmup_steps: number of warmup steps\n",
    "    :param decay_factor: decay factor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, optimizer, initial_lr, min_lr=1e-6, warmup_steps=10, decay_factor=10\n",
    "    ):\n",
    "        self.optimizer = optimizer\n",
    "        self.initial_lr = initial_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.decay_factor = decay_factor\n",
    "\n",
    "        assert self.warmup_steps > 0, \"Warmup steps must be greater than 0\"\n",
    "        assert self.decay_factor > 1, \"Decay factor must be greater than 1\"\n",
    "\n",
    "        self.global_step = 0\n",
    "        self.best_loss = float(\"inf\")\n",
    "\n",
    "        # Store initial learning rates\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group[\"lr\"] = 0  # Start with 0 LR\n",
    "\n",
    "    def step(self, loss):\n",
    "        \"\"\"Update learning rate based on current loss.\"\"\"\n",
    "        self.global_step += 1\n",
    "\n",
    "        if self.global_step <= self.warmup_steps:\n",
    "            # Linear warmup\n",
    "            warmup_lr = self.initial_lr * (self.global_step / self.warmup_steps)\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group[\"lr\"] = warmup_lr\n",
    "        else:\n",
    "            # Check if loss increased\n",
    "            if loss > self.best_loss:\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    new_lr = max(param_group[\"lr\"] / self.decay_factor, self.min_lr)\n",
    "                    param_group[\"lr\"] = new_lr\n",
    "            self.best_loss = min(self.best_loss, loss)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \"\"\"Return current learning rates.\"\"\"\n",
    "        return [param_group[\"lr\"] for param_group in self.optimizer.param_groups]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f83a2e1be44b7",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598910ed9aa13cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = torch.load(file_path, mmap=True) # lazy load\n",
    "        self.eeg = self.data[\"data\"]\n",
    "        self.labels = self.data[\"label\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.eeg[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aca1837b7ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EEGDataset(DATA[\"train_path\"])\n",
    "val_dataset = EEGDataset(DATA[\"val_path\"])\n",
    "test_dataset = EEGDataset(DATA[\"test_path\"])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=ARGS[\"batch\"], shuffle=True\n",
    ")\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=ARGS[\"batch\"])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=ARGS[\"batch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82515c6727501027",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff05fa88cc9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.self_attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        torch._assert(input.dim() == 3, f\"Expected (batch_size, seq_length, hidden_dim) got {input.shape}\")\n",
    "        x = self.ln_1(input)\n",
    "        x, _ = self.self_attention(x, x, x, need_weights=False)\n",
    "        x = self.dropout(x)\n",
    "        x = x + input\n",
    "\n",
    "        y = self.ln_2(x)\n",
    "        y = self.mlp(y)\n",
    "        return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d676552d11f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGTransformer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(EEGTransformer, self).__init__()\n",
    "        self.pos_embedding = nn.Parameter(torch.empty(1, seq_length, hidden_dim).normal_(std=0.02))\n",
    "        self.global_max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(142, 64), nn.Linear(64, 64), nn.Linear(64, 2), nn.Softmax(dim=3)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677eac4f57877cca",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8403dd1c50898b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "model = EEGTransformer().to(DEVICE)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=ARGS[\"lr\"],\n",
    "    weight_decay=ARGS[\"weight_decay\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34319768aa7c130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, val_loader, device, mode=None):\n",
    "    model.eval()\n",
    "    val_loss = list()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, label in val_loader:\n",
    "            label = label.to(device)\n",
    "            input_id = input_ids.to(device)\n",
    "            mask = attention_mask.to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            batch_loss = criterion(output.logits, label.long())\n",
    "            val_loss.append(batch_loss.item())\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "\n",
    "def train(model, optimizer, scheduler, criterion, train_loader, val_loader, device):\n",
    "    clear()\n",
    "\n",
    "    model_path = ARGS[\"model_path\"]\n",
    "    grad_step = ARGS[\"grad_step\"]\n",
    "    epoch_progress = trange(1, ARGS[\"epochs\"] + 1)\n",
    "    early_stopper = EarlyStopping(ARGS[\"patience\"], model_path)\n",
    "\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "    model.zero_grad()\n",
    "\n",
    "    for epoch in epoch_progress:\n",
    "\n",
    "        model.train()\n",
    "        train_loss = list()\n",
    "        for batch_id, data in enumerate(train_loader, start=1):\n",
    "\n",
    "            output = model()\n",
    "\n",
    "            batch_loss = criterion(output.logits, train_label.long())\n",
    "            train_loss.append(batch_loss.item())\n",
    "\n",
    "            batch_loss /= grad_step\n",
    "            batch_loss.backward()\n",
    "\n",
    "            if batch_id % grad_step == 0:\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "\n",
    "        val_loss = evaluate(model, criterion, val_loader, device, mode=\"train\")\n",
    "        train_loss = np.mean(train_loss)\n",
    "        val_loss = np.mean(val_loss)\n",
    "        tqdm.write(\n",
    "            f\"Epoch {epoch}, Train-Loss: {train_loss:.5f},  Val-Loss: {val_loss:.5f}\"\n",
    "        )\n",
    "\n",
    "        if early_stopper.should_stop(model, val_loss):\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    tqdm.write(f\"\\n\\n -- EarlyStopping: [Epoch: {epoch - early_stopper.counter}]\")\n",
    "    tqdm.write(f\"Model saved at '{model_path}'.\")\n",
    "    model = early_stopper.load(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7acf65fbe1b6b3f",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10da8a564d239736",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "auc_value = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9bb9ed56d0d600",
   "metadata": {},
   "source": [
    "## Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bcb229942428",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_result = {\n",
    "    \"id\": ARGS[\"id\"],\n",
    "    \"model_path\": ARGS[\"model_path\"],\n",
    "    \"batch\": (ARGS[\"batch\"], ARGS[\"grad_step\"]), # Batch size with Gradient Accumulation\n",
    "    \"lr\": ARGS[\"lr\"],\n",
    "    \"weight_decay\": ARGS[\"weight_decay\"],\n",
    "    \"accuracy\": accuracy,\n",
    "    \"f1\": f1,\n",
    "    \"auc\": auc_value,\n",
    "}\n",
    "\n",
    "for key, value in experiment_result.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Save result in json format\n",
    "with open(join_path(f\"{ARGS['id']}.json\"), \"w\") as f:\n",
    "    json.dump(experiment_result, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
